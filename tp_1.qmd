---
title: "{{< fa flask >}} **Econom√©trie Appliqu√©e**"
title-block-banner: imgs/apples.png
subtitle: "Des üçè sur {{< fa brands r-project >}} !"
toc: true
toc-title: üìö Table des mati√®res
lang: fr
number-sections: true
author:
  - name: "*Corentin Ducloux*"
    affiliation: 
      - name: Universit√© de Tours
        url: https://www.univ-tours.fr/
  - name: "*Guillaume Devant*"
    affiliation: 
      - name: Universit√© de Tours
        url: https://www.univ-tours.fr/
date: today
date-format: short
include-in-header: 
    - text: | 
        <link href='https://fonts.googleapis.com/css?family=Fira Code' rel='stylesheet'>
format:
    html:
        theme: simplex
        monofont: "Fira Code"
        fontsize: 1em
        embed-resources: true
        html-math-method: mathjax
        code-fold: true 
        anchor-sections: true
        smooth-scroll: true
        citations-hover: true
        footnotes-hover: true
        link-external-icon: true
        link-external-newwindow: true
code-block-bg: "#F1F3F5"
code-block-border-left: "#d9230f"
license: "CC BY-SA"
bibliography: references.bib
crossref:
    eq-prefix: √©quation
    tbl-prefix: Tableau
editor_options: 
    chunk_output_type: console
---

```{css, echo=FALSE}
.img-block {
    margin: auto;
    width: 85%;
    padding: 10px;
    text-align: center;
}
.img-block img {
    display: inline-block;
    margin: auto;
    max-width: 100%;
}
.title {
    color: white;
}
.subtitle {
    color: white;
}
```

***

:::{.img-block}
<br>
<img src="imgs/MECEN_logo.png" alt="MECEN Logo" style="width: 30%;">
<img src="imgs/UT_logo.jpg" alt="UT Logo" style="width: 45%;">

:::

***

```{r}
#| label: functions
#| echo: false

makestars <- function(pvalues) {
    return(
        dplyr::case_when(
            pvalues < 0.001 ~ "$***$",
            pvalues < 0.05 ~ "$**$",
            pvalues < 0.1 ~ "$*$",
            .default = ""
        )
    )
}


gtgazer <- function(model, n_coef = 4, coefnames, description, title, bg_color) {
    if (class(model) %in% c("translogEst")) {
        coefficients <- summary(model)$coefTable[1:n_coef, 1]
        std_values <- summary(model)$coefTable[1:n_coef, 2]
        pvalues <- summary(model)$coefTable[1:n_coef, 4]
        signif <- makestars(pvalues)
        r2 <- round(summary(model)$r2, 3)
        adj_r2 <- round(summary(model)$r2bar, 3)
        n <- summary(model)$nObs
        dep_variable <- summary(model)$yName
    } else if (class(model) %in% c("quadFuncEst", "translogCostEst")) {
        coefficients <- summary(model$est)$coefficients[, 1]
        std_values <- summary(model$est)$coefficients[, 2]
        pvalues <- summary(model$est)$coefficients[, 4]
        signif <- makestars(pvalues)
        r2 <- round(model$r2, 3)
        adj_r2 <- round(model$r2bar, 3)
        n <- model$nObs
        dep_variable <- ifelse(class(model) == "quadFuncEst", model$yName, model$cName)
    } else if (class(model) == "lm") {
        coefficients <- summary(model)$coefficients[, 1]
        std_values <- summary(model)$coefficients[, 2]
        pvalues <- summary(model)$coefficients[, 4]
        signif <- makestars(pvalues)
        r2 <- round(summary(model)$r.squared, 3)
        adj_r2 <- round(summary(model)$adj.r.squared, 3)
        n <- nobs(model)
        dep_variable <- "qOut"
    }

    coefnames <- coefnames
    description <- description
    reg_results <- data.frame(cbind(coefnames, description, coefficients, std_values, pvalues, signif)) |>
        tibble() |>
        mutate(across(c(coefficients, std_values, pvalues), as.numeric))

    table <- reg_results |>
        gt(rowname_col = "coefnames") |>
        cols_label(
            description = md("**Description**"),
            coefficients = md("**Coefficients**"),
            std_values = md("**Ecart Type**"),
            pvalues = md("**Pvalues**"),
            signif = md("**Significativit√©**")
        ) |>
        fmt_markdown(columns = c(coefnames, signif, description)) |>
        fmt_number(
            columns = c(coefficients, pvalues),
            decimals = 3,
            drop_trailing_zeros = TRUE
        ) |>
        fmt(columns = std_values, fns = function(std) {
            paste("+/-", round(std, 3))
        }) |>
        tab_footnote(footnote = md(sprintf("*Observations* : %s", n))) |>
        tab_footnote(footnote = md("***")) |>
        tab_footnote(footnote = md(glue::glue("$R^2=$ {r2}"))) |>
        tab_footnote(footnote = md(glue::glue("$R^2_{{adj}}=$ {adj_r2}"))) |>
        tab_header(
            title = md(title),
            subtitle = md(glue::glue("Variable d√©pendante : `{dep_variable}`"))
        ) |>
        tab_options(
            table.background.color = bg_color
        )

    return(table)
}
```

**TODOS**

- [ ] Test de Fisher √† mettre en place dans la partie fonction de production Translog (vs Cobb Douglas)
- [ ] Ajouter une fonction CES classique avec 2 inputs en plus de la nested CES
- [ ] Rendements d'√©chelle pour la quadratique avec $\lambda$ tr√®s tr√®s bancal
- [x] Changer l'√©criture scientifique des labels des graphs vers une √©criutre en millions (25M)
- [ ] Pour les fonctions de cout mettre les formes fonctionnelles avec nos 3 inputs √† nous

## Imports et configuration

:::{.callout-note}

Tout au long de ce projet, nous utiliserons l'approche [`tidy`](https://www.tidyverse.org/) d√©velopp√©e par @wickham2014 plut√¥t que l'approche `base R` pour manipuler nos donn√©es. De plus, l'utilisation du package `micEcon` et de ses annexes nous facilitera grandement le travail d'estimation -- voir @henningsen2017.

:::

```{r}
#| label: lib_imports
#| warning: false
#| code-fold: false
library(ggplot2)
library(dplyr)
library(tidyr)
library(gt)
library(tibble)
library(patchwork)
library(FactoMineR)
library(factoextra)
library(ggtext)
library(micEcon)
library(micEconSNQP)
library(micEconIndex)
library(micEconCES)
library(frontier)
library(ranger)
library(tuneRanger)
library(mlr)
library(rsample)
library(forcats)
library(performance)
```

```{r}
#| label: colors
#| echo: false
bg_color <- "#FCFCFC"
alpha <- 0.7
```

```{r}
#| label: theming
#| echo: false
theme_set(theme_minimal())
thematic::thematic_on(bg = "#FCFCFC", fg = "black", accent = "purple", font = "PT Sans")
```

## Description des donn√©es

Le jeu de donn√©es `appleProdFr86` utilis√© dans le papier d'√©conom√©trie de @ivaldi1996 comprend des donn√©es transversales de production de **140** producteurs de pommes fran√ßais datant de l‚Äôann√©e 1986. 

```{r}
#| label: data_import
#| code-fold: false
apples <- readxl::read_excel("data/appleProdFr86.xlsx")
```

| Colonnes    | Description                                                                                              |
|-------------|----------------------------------------------------------------------------------------------------------|
| `vCap`      | Co√ªts associ√©s au **capital** *(foncier compris)*.                                                       |
| `vLab`      | Co√ªts associ√©s au **travail** *(y compris la r√©mun√©ration du travail familial non r√©mun√©r√©)*.            |
| `vMat`      | Co√ªts des **mati√®res interm√©diaires** *(plantations, engrais, pesticides, carburant, etc)*.              |
| `qApples`   | Indice de quantit√© des pommes produites.                                                                 |
| `qOtherOut` | Indice de quantit√© de tous les autres outputs.                                                           |
| `qOut`      | Indice de quantit√© de toute la production $\Rightarrow 580000 \cdot (\text{qApples} + \text{qOtherOut})$ |
| `pCap`      | Indice des prix du **capital**.                                                                           |
| `pLab`      | Indice des prix du **travail**.                                                                           |
| `pMat`      | Indice des prix des **mati√®res interm√©diaires**.                                                          |
| `pOut`      | Indice des prix de la production globale.                                                                 |
| `adv`       | Distingue les producteurs qui sont conseill√©s par des laboratoires d'agronomie.                           |

: Descriptif des colonnes {.hover}

### Tableau descriptif {#sec-desc-table}

> Ce tableau descriptif retrace les 10 premi√®res observations et l'ensemble des variables associ√©es dans le *dataset*.

```{r}
#| label: descriptive table
#| echo: false
apples |>
    head(n = 10) |>
    gt() |>
    tab_header(
        title = md("**Producteurs de pommes üçé**"),
        subtitle = md("*140 producteurs* üá´üá∑ *(1986)*")
    ) |>
    tab_source_note(
        source_note = md(
            "`Source`: *Ivaldi et al. (1996)*"
        )
    ) |>
    tab_spanner(
        label = "Costs",
        columns = c("vCap", "vLab", "vMat")
    ) |>
    tab_spanner(
        label = "Price Index",
        columns = c("pCap", "pLab", "pMat", "pOut")
    ) |>
    tab_spanner(
        label = "Quantity Index",
        columns = c("qApples", "qOtherOut", "qOut")
    ) |>
    tab_spanner(
        label = "Factor Quantities",
        columns = c("qCap", "qLab", "qMat")
    ) |>
    tab_style(
        style = list(
            cell_fill(color = "lavenderblush")
        ),
        location = cells_body(columns = c(vCap, vLab, vMat))
    ) |>
    tab_style(
        style = list(
            cell_fill(color = "ivory")
        ),
        location = cells_body(columns = c(qApples, qOtherOut, qOut))
    ) |>
    tab_style(
        style = list(
            cell_fill(color = "aliceblue")
        ),
        location = cells_body(columns = c(pCap, pLab, pMat, pOut))
    ) |>
    fmt_number(suffixing = TRUE, n_sigfi = 2) |>
    text_case_match(
        "1.0" ~ fontawesome::fa("check"),
        "0" ~ fontawesome::fa("xmark"),
        .locations = cells_body(columns = adv)
    ) |>
    cols_label(
        N = md("$N$"),
        vCap = md("$v_{Cap}$"),
        vLab = md("$v_{Lab}$"),
        vMat = md("$v_{Mat}$"),
        qApples = md("$q_{Apples}$"),
        qOtherOut = md("$q_{OtherOut}$"),
        qOut = md("$q_{Out}$"),
        pCap = md("$p_{Cap}$"),
        pLab = md("$p_{Lab}$"),
        pMat = md("$p_{Mat}$"),
        pOut = md("$p_{Out}$"),
        adv = md("$adv$"),
        qCap = md("$q_{Cap}$"),
        qLab = md("$q_{Lab}$"),
        qMat = md("$q_{Mat}$")
    ) |>
    tab_options(
        table.background.color = bg_color
    )
```

## Statistiques descriptives

### Productivit√© moyenne des facteurs de production {#sec-ap-prod}

La productivit√© moyenne ($AP =$ **Average Product**) consiste √† diviser la quantit√© totale d'output par la quantit√© totale de facteur utilis√© *(input)* dans le processus de production.

Imaginons que les unit√©s d'output sont des tonnes. Pour chaque input, cela revient en fait √† expliquer combien de tonnes sont produites **en moyenne** par unit√© de capital, de travail et de mati√®res interm√©diaires en 1986 pour chaque producteur de pommes.

Nous obtenons alors respectivement :

- $AP_{Cap} = \frac{q_{Out}}{q_{Cap}}$

- $AP_{Lab} = \frac{q_{Out}}{q_{Lab}}$

- $AP_{Mat} = \frac{q_{Out}}{q_{Mat}}$


```{r}
#| label: productivites
#| code-fold: false
apples <- apples |> mutate(
    AP_Cap = qOut / qCap,
    AP_Lab = qOut / qLab,
    AP_Mat = qOut / qMat
)
```

```{r}
#| label: table_AP
#| echo: false
tibble_AP_Cap <- apples |>
    summarise(min = min(AP_Cap), mean = mean(AP_Cap), max = max(AP_Cap), std = sd(AP_Cap)) |>
    add_column(type = "$AP_{Cap}$", .before = "min")
tibble_AP_Lab <- apples |>
    summarise(min = min(AP_Lab), mean = mean(AP_Lab), max = max(AP_Lab), std = sd(AP_Lab)) |>
    add_column(type = "$AP_{Lab}$", .before = "min")
tibble_AP_Mat <- apples |>
    summarise(min = min(AP_Mat), mean = mean(AP_Mat), max = max(AP_Mat), std = sd(AP_Mat)) |>
    add_column(type = "$AP_{Mat}$", .before = "min")

AP_table <- bind_rows(tibble_AP_Cap, tibble_AP_Lab, tibble_AP_Mat)

AP_table |>
    gt() |>
    fmt_markdown(columns = type) |>
    fmt_number(columns = c(-type)) |>
    tab_header(
        title = md("**Productivit√© Moyenne par Facteur üìã**"),
        subtitle = md("*Capital --- Travail --- Mat√©riaux*")
    ) |>
    cols_label(
        min = md("$\\min$"),
        mean = md("$\\mu$"),
        max = md("$\\max$"),
        std = md("$\\sigma^2$"),
        type = ""
    ) |>
    tab_options(
        table.background.color = bg_color
    )
```

Ce tableau, en plus des visualisations qui vont suivre, permet d'√©tablir que les productivit√©s moyennes par facteur sont **tr√®s diff√©rentes selon les producteurs**. De plus, on s'aper√ßoit aussi qu'investir dans un facteur particulier peut √™tre plus int√©ressant qu'un autre. 

C'est particuli√®rement vrai pour le facteur `Mat` avec une productivit√© moyenne minimale de **8.22** unit√©s d'output pour une unit√© de mat√©riaux et jusqu'√† **301.43** unit√©s d'output pour une unit√© de mat√©riaux.

```{r}
#| label: AP_plots
#| echo: false
#| fig-align: center
apples |>
    ggplot() +
    aes(x = AP_Cap) +
    geom_histogram(binwidth = 1.25, fill = "darkgreen", alpha = alpha) +
    labs(
        title = "Productivit√© Moyenne du Capital", subtitle = "Pour une unit√© de capital, combien d'unit√©s d'output sont produits ?", x = "", y = "Fr√©quence",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    )

apples |>
    ggplot() +
    aes(x = AP_Lab) +
    geom_histogram(binwidth = 0.75, fill = "orange", alpha = alpha) +
    labs(
        title = "Productivit√© Moyenne du Travail", subtitle = "Pour une unit√© de travail, combien d'unit√©s d'output sont produits ?", x = "", y = "Fr√©quence",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    )

apples |>
    ggplot() +
    aes(x = AP_Mat) +
    geom_histogram(binwidth = 1.5, fill = "darkorchid", alpha = alpha) +
    labs(
        title = "Productivit√© Moyenne des mat√©riaux", subtitle = "Pour une unit√© de mat√©riaux, combien d'unit√©s d'output sont produits ?", x = "", y = "Fr√©quence",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    )
```

### Corr√©lations entre les quantit√©s des 3 facteurs de production

```{r}
#| label: q_matrix
#| echo: false
apples |>
    select(qCap, qLab, qMat) |>
    cor() |>
    round(2) |>
    data.frame() |>
    gt() |>
    tab_header(title = md("**Matrice de corr√©lation**")) |>
    cols_add(type = c("$q_{Cap}$", "$q_{Lab}$", "$q_{Mat}$")) |>
    cols_move_to_start(columns = type) |>
    fmt_markdown(type) |>
    cols_label(
        type = "",
        qCap = md("$q_{Cap}$"),
        qLab = md("$q_{Lab}$"),
        qMat = md("$q_{Mat}$"),
    ) |>
    tab_options(
        table.background.color = bg_color
    )
```

- Les quantit√©s des 3 facteurs de production sont toutes corr√©l√©es positivement.

- On s'aper√ßoit que la corr√©lation **positive** la plus importante est entre $q_{Lab}$ et $q_{Mat}$ $\Rightarrow$ cela implique que lorsque la quantit√© de travail augmente, la quantit√© de mat√©riaux a tendance √† augmenter dans un niveau tr√®s similaire, et *vice versa*.

### Corr√©lations entre les productivit√©s moyennes

Essayons maintenant de comprendre comment les productivit√©s moyennes individuelles sont corr√©l√©es :

```{r}
#| label: ap_matrix
#| echo: false
apples |>
    select(starts_with("AP")) |>
    cor() |>
    round(2) |>
    data.frame() |>
    gt() |>
    tab_header(title = md("**Matrice de corr√©lation**")) |>
    cols_add(type = c("$AP_{Cap}$", "$AP_{Lab}$", "$AP_{Mat}$")) |>
    cols_move_to_start(columns = type) |>
    fmt_markdown(type) |>
    cols_label(
        type = "",
        AP_Cap = md("$AP_{Cap}$"),
        AP_Lab = md("$AP_{Lab}$"),
        AP_Mat = md("$AP_{Mat}$")
    ) |>
    tab_options(
        table.background.color = bg_color
    )
```

- Ces r√©sultats nous sugg√®rent l'existence de relations positives entre les productivit√©s moyennes des diff√©rents facteurs de production dans le processus de production. 

- Ici, une augmentation de la productivit√© moyenne du travail peut √™tre associ√©e √† une augmentation **significative** de la productivit√© moyenne des mat√©riaux, ce qui peut √™tre d√ª √† des facteurs tels que des processus de production plus efficaces ou une meilleure utilisation des ressources de la part du producteur de pommes.

***


```{r}
#| label: prod_plots
#| echo: false
#| fig-align: center
CL <- apples |>
    ggplot() +
    aes(x = AP_Cap, y = AP_Lab) +
    geom_point(colour = "slategray", alpha = alpha) +
    labs(x = expression(AP[Cap]), y = expression(AP[Lab]))
ML <- apples |>
    ggplot() +
    aes(x = AP_Mat, y = AP_Lab) +
    geom_point(colour = "gray", alpha = alpha) +
    labs(x = expression(AP[Mat]), y = expression(AP[Lab]))
CM <- apples |>
    ggplot() +
    aes(x = AP_Cap, y = AP_Mat) +
    geom_point(colour = "gray21", alpha = alpha) +
    labs(x = expression(AP[Cap]), y = expression(AP[Mat]))

prod_plots <- (CL + ML) / CM

prod_plots + plot_annotation(
    title = "Croisement des productivit√©s moyennes",
    subtitle = "Quelles sont les relations existantes entre les diff√©rentes productivit√©s moyennes ?",
    caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
)
```

::: {.callout-note}

Les repr√©sentations des productivit√©s moyennes $AP_{Cap}$, $AP_{Lab}$ et $AP_{Mat}$ par rapport √† l'output $q_{Out}$ peuvent aussi √™tre tr√®s utiles pour comprendre les relations entre la production totale et l'utilisation des diff√©rents facteurs de production.

:::

```{r}
#| label: qout_plots
#| echo: false
#| fig-align: center
QC <- apples |>
    ggplot() +
    aes(y = qOut, x = AP_Cap) +
    geom_point(colour = "darkgreen", alpha = alpha) +
    labs(x = expression(AP[Cap]), y = "") +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    )
QL <- apples |>
    ggplot() +
    aes(y = qOut, x = AP_Lab) +
    geom_point(colour = "orange", alpha = alpha) +
    labs(x = expression(AP[Lab]), y = "") +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    )
QM <- apples |>
    ggplot() +
    aes(y = qOut, x = AP_Mat) +
    geom_point(colour = "darkorchid", alpha = alpha) +
    labs(x = expression(AP[Mat]), y = "") +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    )

qOut_prod_plots <- (QC + QL) / QM

qOut_prod_plots + plot_annotation(
    title = "Productivit√© moyenne par rapport √† l'output total",
    subtitle = "Quelles sont les relations existantes entre les productivit√©s moyennes des inputs et de l'output ?",
    caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
)
```

- Les valeurs extr√™mes dans ces nuages de points nous permettent de distinguer ais√©ment les producteurs *efficaces* et *inefficaces* dans l'utilisation des ressources.

### Indices de Paasche, Laspeyres et Fisher

Les productivit√©s moyennes nous donnent une indication facteur par facteur, mais elles ne nous donnent pas n√©cessairement d'information **globale**. Dans ce cadre, on peut alors se demander comment agr√©ger des quantit√©s avec une r√®gle *ad hoc* en un indice synth√©tique.

**3 Indices principaux existent**

::: {.callout-tip}

## Indice de *Paasche*

$$
\text{Paasche}_{index} = \frac{(v_{Cap} + v_{Lab} + v_{Mat})}{{\bar{q}_{Cap}}\cdot p_{Cap} + \bar{q}_{Lab}\cdot p_{Lab} + \bar{q}_{Mat} \cdot p_{Mat}}
$$

:::

::: {.callout-tip}

## Indice de *Laspeyres*

$$
\text{Laspeyres}_{index} = \frac{(q_{Cap} \cdot \bar{p}_{Cap} + q_{Lab} \cdot \bar{p}_{Lab} + q_{Mat} \cdot \bar{p}_{Mat})}{(\bar{q}_{Cap}\cdot \bar{p}_{Cap}+\bar{q}_{Lab}\cdot \bar{p}_{Lab}+\bar{q}_{Mat}\cdot \bar{p}_{Mat})}
$$

:::

::: {.callout-tip}

## Indice de *Fisher*

$$
\text{Fisher}_{index} = \sqrt{\text{Paasche}_{index} \cdot \text{Laspeyres}_{index}}
$$

:::

De plus, la fonction `quantityIndex` du package `micEconIndex` a l'int√©r√™t de facilement int√©grer les calculs de chaque indice *(Voir ci-dessous)*.

```{r}
#| label: q_index
#| code-fold: false
apples <- apples |> mutate(
    L_Index = quantityIndex(
        prices = c("pCap", "pLab", "pMat"),
        quantities = c("qCap", "qLab", "qMat"),
        data = apples,
        method = "Laspeyres"
    ),
    P_Index = quantityIndex(
        prices = c("pCap", "pLab", "pMat"),
        quantities = c("qCap", "qLab", "qMat"),
        data = apples,
        method = "Paasche"
    ),
    F_Index = quantityIndex(
        prices = c("pCap", "pLab", "pMat"),
        quantities = c("qCap", "qLab", "qMat"),
        data = apples,
        method = "Fisher"
    )
)
```

```{r}
#| label: q_index_plots
#| echo: false
#| warning: false
#| fig-align: center
apples |>
    ggplot() +
    aes(x = P_Index, y = L_Index) +
    geom_point() +
    geom_smooth(method = lm, se = FALSE) +
    labs(
        x = "Paasche Index",
        y = "Laspeyres Index",
        title = "Relation entre l'indice de Paasche & de Laspeyres"
    ) +
    theme(legend.position = "None")
```

D'apr√®s cette visualisation on peut conclure que faire le choix de l'indice de *Paasche* ou de *Laspeyres* revient sensiblement √† la m√™me interpr√©tation. 

*Note* : Etant donn√© que l'indice de *Fisher* est une moyenne g√©om√©trique des deux indices, il n'est pas non plus n√©cessaire de le repr√©senter puisque la relation lin√©aire entre les deux indices sera presque parfaite dans ce cas.

***

```{r}
#| label: f_index_matrix
#| echo: false
apples |>
    select(AP_Cap, AP_Lab, AP_Mat, F_Index) |>
    cor() |>
    round(2) |>
    data.frame() |>
    gt() |>
    tab_header(md("**Matrice de corr√©lation**")) |>
    tab_style(
        style = list(
            cell_fill(color = "gray95")
        ),
        locations = cells_body(columns = F_Index)
    ) |>
    cols_add(
        type = c("$AP_{Cap}$", "$AP_{Lab}$", "$AP_{Mat}$", "$\\text{Fisher}_{index}$")
    ) |>
    cols_move_to_start(columns = type) |>
    fmt_markdown(type) |>
    cols_label(
        type = "",
        AP_Cap = md("$AP_{Cap}$"),
        AP_Lab = md("$AP_{Lab}$"),
        AP_Mat = md("$AP_{Mat}$"),
        F_Index = md("$\\text{Fisher}_{index}$")
    ) |>
    tab_style(
        style = cell_fill(color = "gray95"),
        locations = cells_body(rows = c(4))
    ) |>
    tab_options(
        table.background.color = bg_color
    )
```

- Ces r√©sultats sugg√®rent que l'indice de *Fisher* n'est pas fortement corr√©l√© avec les productivit√©s moyennes individuelles des facteurs de production.

### Productivit√© globale des facteurs

- Dans la section pr√©c√©dente, nous avons montr√© que les indices donnaient sensiblement les m√™mes r√©sultats. Nous avons n√©anmoins choisi en tant qu'indice de productivit√© globale des facteurs l'indice de *Fisher*, √©tant donn√© qu'il est une moyenne g√©om√©trique de l'indice de *Paasche* et de celui de *Laspeyres*.

```{r}
#| label: f_index_hist
#| echo: false
#| fig-align: center
apples |>
    ggplot() +
    aes(x = F_Index) +
    geom_histogram(binwidth = 0.25, fill = "darkred", alpha = 0.7) +
    labs(title = "Productivit√© globale (Indice de Fisher)", x = "Valeur de l'indice", y = "Fr√©quence", caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 ")
```

- De mani√®re int√©ressante, contrairement aux histogrammes des productivit√©s moyennes de la @sec-ap-prod, la plupart des valeurs que prend l'indice de *Fisher* sont plus concentr√©es.

```{r}
#| label: f_index_plots
#| echo: false
#| fig-align: center
apples |>
    ggplot() +
    aes(y = qOut, x = F_Index) +
    geom_point(colour = "darkorchid", alpha = alpha) +
    labs(
        title = "Relation entre l'indice de productivit√© globale des facteurs et l'output", y = "", x = "Indice de Fisher",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    )
```

::: {.callout-note}

La variable dichotomique `adv` pr√©sente dans notre *dataset* est d√©finie par :

$$
adv = 
\begin{cases}
0 \text{ si le producteur n'est pas conseill√©}\\
1 \text{ si le producteur est conseill√©}
\end{cases}
$$

On pourrait penser que les producteurs qui ont √©t√© conseill√©s par des laboratoires d'agronomie ont un indice de productivit√© globale plus important que ceux qui ne l'ont pas √©t√©. 

**V√©rifions-le graphiquement et statistiquement**

:::

```{r}
#| label: advice_boxplot
#| echo: false
#| fig-align: center
apples <- apples |> mutate(
    adv_chr = case_when(
        adv == 0 ~ "No advice",
        adv == 1 ~ "Advice",
    )
)

apples |>
    ggplot() +
    aes(y = F_Index, x = adv_chr, fill = adv_chr) +
    geom_boxplot() +
    labs(
        title = "Productivit√© globale en fonction du conseil ou non d'un laboratoire", x = "", y = "",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    theme(legend.position = "None")

apples_grouped <- apples |>
    select(adv_chr, F_Index) |>
    group_by(adv_chr) |>
    summarise(mean = mean(F_Index))

mean_advice <- apples_grouped |>
    slice(1) |>
    pull()

mean_no_advice <- apples_grouped |>
    slice(2) |>
    pull()
```

- En moyenne, il semble ne pas y avoir de diff√©rence de productivit√© globale lorsque le producteur est conseill√©. En effet, la productivit√© moyenne avec conseil est √©gale √† `r round(mean_advice,2)` tandis que la productivit√© moyenne sans conseil est quant √† elle √©gale √† `r round(mean_no_advice,2)`.

On peut aussi s'assurer que les moyennes sont significativement diff√©rentes en faisant un test de *Student* bilat√©ral :

$$
\begin{cases}
H_0:\mu_{advice} =\mu_{no\_advice}\\
H_1:\mu_{advice} \neq\mu_{no\_advice}
\end{cases}
$$


```{r}
#| label: advice_ttest
#| echo: false
advice <- apples |>
    select(adv_chr, F_Index) |>
    filter(adv_chr == "Advice") |>
    pull()

no_advice <- apples |>
    select(adv_chr, F_Index) |>
    filter(adv_chr == "No advice") |>
    pull()

t_test <- t.test(advice, no_advice, var.equal = F)
pval_t_test <- t_test$p.value
```

$\Rightarrow$ Au risque $\alpha = 5\%$, la $p-value$ issue du test est √©gale √† `r  round(pval_t_test,2)` $> 0.05$, **on conserve donc l'hypoth√®se nulle $H_0$, c'est √† dire qu'il n'y a pas de diff√©rence significative dans les productivit√©s globales quand le producteur est conseill√©/ qu'il ne l'est pas.**


## Analyse exploratoire

### Analyse en composantes principales

L'analyse en composantes principales (ACP) que nous nous appr√™tons √† faire est justifi√©e dans notre contexte car nous n'avons que des variables num√©riques.

```{r}
#| label: pca_biplot
#| echo: false
#| fig-align: center
apples_pca <- apples[-c(96, 129), ] |> select(-c(N, adv_chr))

# On retire les individus 96 et 129 de l'ACP

acp <- PCA(apples_pca, graph = FALSE)

fviz_screeplot(
    acp,
    ylab = "",
    barfill = "royalblue",
    barcolor = "royalblue",
    caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
)

```

Les deux premiers axes concentrent 60% de la variance. Nous allons d√®s lors limiter notre **ACP** √† l‚Äô√©tude de ces axes.

```{r}
#| label: pca_contrib
#| echo: false
#| fig-align: center
contrib_ax_1 <- fviz_contrib(
    acp,
    choice = "var",
    axes = 1,
    fill = "royalblue",
    color = "royalblue"
)

contrib_ax_2 <- fviz_contrib(
    acp,
    choice = "var",
    axes = 2,
    fill = "royalblue",
    color = "royalblue"
)

contrib_ax_1 + contrib_ax_2 + plot_annotation(caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 ")
```

- **Axe 1** $\Rightarrow$ Combinaison de variables : synth√©thise les indices de *Fisher*, *Paasche* et *Laspeyres* (`F_Index`, `P_Index`, `L_Index`), ainsi que les quantit√©s (`qOut`, `qLab`, `qCap`, `qMat`) et les co√ªts des 3 facteurs de production (`vMat`, `vLab`, `vCap`).

- **Axe 2** $\Rightarrow$ Productivit√©s moyennes (`AP_Cap`,`AP_Mat`,`AP_Lab`) et prix de vente de la production (`pOut`)

```{r}
#| label: pca_biplot_2
#| echo: false
#| fig-align: center
fviz_pca_biplot(acp,
    repel = TRUE,
    title = "ACP - Biplot",
    label = "var",
    col.var = "royalblue",
    col.ind = "orange",
    axes = c(1, 2),
    caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
)
```

Dans notre **ACP**, on ne constate pas de variables qui sont fortement oppos√©es. Elle permet n√©anmoins de mettre en avant le lien entre les quantit√©s des facteurs de production et leur valeur. On observe √©galement que le prix de vente est √©troitement li√© avec les productivit√©s moyennes.

### Bonus : La r√©partition de `qOut`

Lorsque l'on s'int√©resse √† la distribution de `qOut` et que l'on met ces valeurs en logarithme, on remarque une distribution proche d'une loi normale. Cette observation est confirm√©e par le test de Shapiro effectu√© ci-dessous. 

```{r}
#| label: norm_density
#| echo: false
#| fig-align: center

apples |>
    ggplot(aes(x = log(qOut))) +
    geom_histogram(aes(y = after_stat(density)),
        alpha = 0.6,
        bins = 25,
        fill = "royalblue",
        color = "royalblue"
    ) +
    labs(
        x = "log(qOut)",
        y = "Fr√©quence",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    theme(plot.title = element_markdown(face = "bold", size = 15)) +
    ggtitle("Densit√© <span style='color:royalblue'>log(qOut)</span> vs. <span style='color:darkred'>loi normale</span>") +
    geom_density(
        color = "royalblue",
        linewidth = 1
    ) +
    stat_function(
        fun = dnorm,
        args = list(
            mean = mean(log(apples$qOut)),
            sd = sd(log(apples$qOut))
        ),
        color = "darkred",
        linewidth = 1
    )
```

$$
\begin{cases}
H_0: \ln(q_{Out})\text{ suit une distribution normale} \\
H_1: \ln(q_{Out})\text{ ne suit pas une distribution normale}
\end{cases}
$$

```{r}
pval_shap_test <- shapiro.test(log(apples$qOut))$p.value
```

$\Rightarrow$ Au seuil $\alpha = 5\%$, le test de *Shapiro* confirme statistiquement le fait que les donn√©es `ln(qOut)` suivent une distribution normale avec une $p-value$ = `r  round(pval_shap_test,2)` soit $> 0.05$, donc $H_0$ n'est pas rejet√©.

## Fonctions de production

> Une fonction de production repr√©sente la relation entre les quantit√©s des diff√©rents facteurs de production utilis√©s (ici `qCap`, `qLab`, `qMat`) et la quantit√© de production obtenue (ici `qOut`).

### Fonction de production lin√©aire

:::{.callout-tip}

## Forme de la fonction

$$
q_i = \alpha + \sum_{k=1}^3\beta_k x_{ik} + Œµ_i
$$

- La **fonction de production lin√©aire** dans notre cas s'√©crit donc sous la forme :

$$
q_{Out} = \alpha + \beta_1 q_{Cap} + \beta_2 q_{Lab} + \beta_3 q_{Mat} + Œµ_i
$$

:::

On a pu constater un lien ind√©niable entre la quantit√© produite (`qOut`) et les productivit√©s moyennes. On peut alors l√©gitimement penser qu'il existe une relation entre la quantit√© produite et les quantit√©s des facteurs de production.

**Avant de s'aventurer dans des formes fonctionnelles plus complexes, commen√ßons par utiliser une simple fonction de production lin√©aire.**

```{r}
#| label: linreg_prod
#| code-fold: false
linreg_prod <- lm(qOut ~ qCap + qLab + qMat, data = apples)
```

```{r}
#| label: linreg_prod_table
#| echo: false
gtgazer(
    linreg_prod,
    n_coef = 4,
    coefnames = c("$\\alpha$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$"),
    description = c(
        "- Constante du mod√®le",
        "- Coefficient associ√© √† la variable `qCap`",
        "- Coefficient associ√© √† la variable `qLab`",
        "- Coefficient associ√© √† la variable `qMat`"
    ),
    title = "**Fonction de production lin√©aire**",
    bg_color = bg_color
)
```

- Le coefficient associ√© √† `qCap` est de 1.788, mais il n'est pas statistiquement significatif, ce qui sugg√®re que la quantit√© de capital n'a pas une influence significative sur la production totale.

- Le coefficient associ√© √† `qLab` est de 11.831 avec un niveau de significativit√© tr√®s √©lev√©, ce qui signifie que pour chaque unit√© suppl√©mentaire de travail utilis√©e, la production totale augmente en moyenne de 11.831 unit√©s, *ceteris paribus*. Cela rev√®le une fois de plus l'influence importante de la quantit√© de travail sur la quantit√© d'output.

- Le coefficient associ√© √† `qMat` est de 46.668 avec un niveau de significativit√© tr√®s √©lev√©, ce qui indique que pour chaque unit√© suppl√©mentaire de mat√©riaux utilis√©s, la production totale augmente en moyenne de 46.668 unit√©s, *ceteris paribus*.

$R^2_{adj}=$ 0.782 donc 78.2% de la variance de la production totale est expliqu√©e par la variance des variables explicatives.

```{r}
#| label: heterosced_investigate
#| echo: false
predicted_qOut <- predict(linreg_prod) |>
    as_tibble() |>
    rename(predicted_qOut = value)
qOut <- apples |> select(qOut)

residuals <- resid(linreg_prod) |>
    as_tibble() |>
    rename(residuals = value)

bind_cols(qOut, predicted_qOut, residuals) |>
    mutate(diff = predicted_qOut / qOut) |>
    arrange(diff) |>
    gt() |>
    tab_header(title = md("üîé Comparaison de la **production effective** et de la **production pr√©dite**")) |>
    cols_label(
        qOut = md("$q_{Out}$"),
        predicted_qOut = md("$\\widehat{q_{Out}}$"),
        residuals = md("$\\varepsilon_i$"),
        diff = md("$\\widehat{q_{Out}}/q_{Out}$")
    ) |>
    fmt_number(suffixing = TRUE, n_sigfi = 2) |>
    cols_align("center") |>
    tab_options(
        table.background.color = bg_color
    ) |>
    opt_interactive(use_highlight = TRUE)
```

La multicolin√©arit√© est un probl√®me qui survient lorsque certaines variables explicatives du mod√®le mesurent le **m√™me ph√©nom√®ne**.

Une multicolin√©arit√© importante peut s‚Äôav√©rer probl√©matique, car elle peut augmenter la variance des coefficients de r√©gression et ainsi les rendre instables. 

```{r}
#| label: vif_lin
#| warning: false
#| echo: false
#| fig-align: center

collinearity_lin <- check_collinearity(linreg_prod, verbose = FALSE) |>
    as_tibble()

ggplot(collinearity_lin, aes(x = Term, y = VIF)) +
    geom_point(size = 3.5, color = "darkgreen") +
    geom_pointrange(aes(ymin = VIF_CI_low, ymax = VIF_CI_high), color = "darkgreen") +
    geom_rect(aes(xmin = 0, xmax = 4, ymin = 0, ymax = 5), fill = "green", alpha = 0.01) +
    labs(
        title = "Etude des VIF",
        subtitle = "Pour la fonction de production lin√©aire",
        x = "",
        y = ""
    ) +
    ylim(0, 5)
```

Les **VIF** *(Variance Inflation Factor)* estiment de combien la variance d‚Äôun coefficient est augment√©e en raison d‚Äôune relation lin√©aire avec d‚Äôautres pr√©dicteurs. 

- Ici, les **VIF** sont faibles $(<5)$, il n'y a donc pas de raison de s'inqui√©ter concernant une √©ventuelle multicolin√©arit√©

#### Sp√©cification de la forme fonctionnelle

On peut utiliser un **RESET** test pour v√©rifier si la forme fonctionnelle lin√©aire est la bonne sp√©cification.

$$
\begin{cases}
H_0 : \text{La relation entre la variable a predire et un ou plusieurs predicteurs est lineaire} \\
H_1 : \text{La relation entre la variable a predire et un ou plusieurs predicteurs est quadratique}
\end{cases}
$$

```{r}
#| label: reset_linreg
#| echo: false
reset_linreg_prod <- resettest(linreg_prod, power = 2)
```

$\Rightarrow$ Au risque $\alpha = 5\%$, la $p-value$ issue du test est $< 0.05$, **on rejette donc l'hypoth√®se nulle $H_0$, c'est √† dire qu'on va pr√©f√©rer prendre une forme fonctionnelle incluant des effets quadratiques.**

```{r}
#| label: ppc_linreg_prod
#| warning: false
#| echo: false
#| fig-align: center
aic_linreg_prod <- AIC(linreg_prod)
loglik_linreg_prod <- logLik(linreg_prod)[1]
# check_posterior_predictions(linreg_prod, verbose = FALSE)
```

::: {.callout-caution}

## Inconv√©nients de la forme fonctionnelle lin√©aire

Malgr√© un $R^2_{adj}$ proche de 0.8, ce qui signifie que le mod√®le a plut√¥t un bon ajustement, la sp√©cification lin√©aire poss√®de plusieurs probl√®mes :

1. Les rendements d'√©chelle sont fix√©s comme constants dans la forme fonctionnelle.
2. Elle ne permet pas d'√©valuer les possibilit√©s de substitution entre les trois facteurs de production.

$\Rightarrow$ Face √† ces inconv√©nients du mod√®le lin√©aire, la fonction **Cobb-Douglas** permet de fournir une r√©ponse au point *(1)*.

:::

### Fonction de production Cobb-Douglas {#sec-cobb-prod}

:::{.callout-tip}

## Forme de la fonction

$$
q_i = A \prod_{k=1}^3 x_{ik}^{a_k}Œµ_i
$$

- La **fonction de production Cobb-Douglas** dans notre cas s'√©crit donc sous la forme :

$$
q_{Out} = A\cdot q_{Cap}^\alpha \cdot q_{Lab}^\beta \cdot q_{Mat}^\gamma \cdot Œµ_i
$$

On peut aussi facilement lin√©ariser la fonction pour pouvoir la pr√©parer √† une proc√©dure `lm`, d√®s lors on obtient :

$$
\ln(q_{out}) = \ln(A) + \alpha \cdot \ln(q_{Cap}) + \beta \cdot \ln(q_{Lab}) + \gamma \cdot \ln(q_{Mat}) +  \ln{(Œµ_i)}
$$

:::

Le package `micEcon` propose n√©anmoins l'estimation d'une fonction de production **Cobb-Douglas** gr√¢ce √† la fonction `translogEst` et l'argument `linear = TRUE`^[Gr√¢ce √† cet argument, on restreint en fait les coefficients de tous les termes *quadratiques* et d'*interaction* √† z√©ro, ce qui revient √† estimer une fonction **Cobb-Douglas**.].

```{r}
#| label: cd_prod
#| code-fold: false
cd_prod <- translogEst(
    "qOut",
    c("qCap", "qLab", "qMat"),
    data = apples,
    linear = TRUE
)
```

```{r}
#| label: cd_prod_table
#| echo: false
gtgazer(
    cd_prod,
    n_coef = 4,
    coefnames = c("$A$", "$\\alpha$", "$\\beta$", "$\\gamma$"),
    description = c(
        "- Constante du mod√®le",
        "- Coefficient associ√© √† la variable `qCap`",
        "- Coefficient associ√© √† la variable `qLab`",
        "- Coefficient associ√© √† la variable `qMat`"
    ),
    title = "**Fonction de production Cobb-Douglas**",
    bg_color = bg_color
)
```

```{r}
#| label: cd_prod_metrics
#| echo: false
apples <- apples |> mutate(
    log_qOut = log(qOut),
    log_qCap = log(qCap),
    log_qLab = log(qLab),
    log_qMat = log(qMat)
)

cd_prod_2 <- lm(
    log_qOut ~ log_qCap + log_qLab + log_qMat,
    data = apples
)

aic_cd_prod <- AIC(cd_prod_2)
bic_cd_prod <- BIC(cd_prod_2)
loglik_cd_prod <- logLik(cd_prod_2)[1]
```

Dans le cadre de cette r√©gression, √©tant donn√© que le mod√®le est sous forme $\log-\log$, on peut interpr√©ter les 3 coefficients comme des √©lasticit√©s partielles :

- $\alpha \Rightarrow$ Un changement d'un pourcent de `qCap` induit un changement de 0.163% de `qOut`, *ceteris paribus*. 

- $\beta \Rightarrow$ Un changement d'un pourcent de `qLab` induit un changement de 0.676% de `qOut`, *ceteris paribus*. 

- $\gamma \Rightarrow$ Un changement d'un pourcent de `qMat` induit un changement de 0.627% de `qOut`, *ceteris paribus*.

> *Note* : les coefficients sont significatifs au seuil de 10% pour `qCap`, 1% pour `qLab` et 1% pour `qMat`.

- Le $R^2_{adj}=$ 0.585. On ne peut cependant pas directement comparer les $R^2_{adj}$ entre les fonctions de production lin√©aires et **Cobb-Douglas** puisque les variables d√©pendantes ne sont pas les m√™mes. 

```{r}
#| label: cd_prod_posterior
#| fig-align: center
check_posterior_predictions(cd_prod_2)
```

#### Rendements d'√©chelle

On l'a vu ci-dessus, les exposants $\alpha$, $\beta$ et $\gamma$ sont les √©lasticit√©s de la production, c'est-√†-dire qu'ils mesurent respectivement le changement en pourcentage de l'output aux variations en pourcentage de la quantit√© de capital, de la quantit√© de travail et de la quantit√© de mat√©riaux.

- Gr√¢ce √† ces coefficients estim√©s, on peut d√©terminer les rendements d'√©chelle.

::: {.callout-note}

## Note sur les rendements d'√©chelle

- **D√©croissants** si $\hat{\alpha} + \hat{\beta} + \hat{\gamma} < 1$

- **Constants** si $\hat{\alpha} + \hat{\beta} + \hat{\gamma} = 1$

- **Croissants** si $\hat{\alpha} + \hat{\beta} + \hat{\gamma} > 1$

:::

```{r}
#| label: return_to_scale
#| code-fold: false
alpha <- cd_prod$coef[2] |> unname()
beta <- cd_prod$coef[3] |> unname()
gamma <- cd_prod$coef[4] |> unname()

return_to_scale <- alpha + beta + gamma
```

- On trouve que $\hat{\alpha} + \hat{\beta} + \hat{\gamma} =$ **`r round(return_to_scale, 2)`**, donc les rendements d'√©chelles sont croissants, c'est √† dire que le processus de production pr√©sente des *√©conomies d‚Äô√©chelle*. Un accroissement identique de tous les facteurs conduit √† un
accroissement plus important de la production. 

- Ces rendements d‚Äô√©chelle croissants sont souvent le r√©sultat de co√ªts fixes √©lev√©s *(voir la @sec-desc-table pour s'en convaincre)*.

> Une implication de ce r√©sultat est que des installations de production √† grande √©chelle ont tendance √† √™tre plus efficaces que des installations √† petite √©chelle.

***

**Int√©ressons-nous √† l‚Äô√©lasticit√© de substitution, qui mesure la facilit√© avec laquelle un input peut √™tre substitu√© par un autre.**

- Si l'elasticit√© de substitution n'est pas empiriquement estimable pour la **Cobb-Douglas**, celle-ci suppose implicitement que l'√©lasticit√© de substitution de *Allen* est √©gale √† un, soit $\sigma_{\{\text{qCap, qLab, qMat}\}} = 1$. 

- Cela implique une substitution **parfaite** entre les facteurs de production $q_{Cap}$, $q_{Lab}$ et $q_{Mat}$, **ce qui va clairement √† l'encontre des r√©sultats de la @sec-ap-prod**. 

#### Productivit√© marginale des inputs

La productivit√© marginale se r√©f√®re √† la variation de la production totale r√©sultant d'une petite variation d'un facteur de production sp√©cifique, *toutes choses √©gales par ailleurs*.

En d'autres termes, il s'agit de la quantit√© suppl√©mentaire d'output qu'une entreprise peut produire en utilisant une unit√© suppl√©mentaire d'un facteur de production donn√©, tout en maintenant constantes les quantit√©s des autres facteurs de production.

Nous obtenons alors respectivement :

- $MP_{Cap} = \frac{\partial q_{Out}}{\partial q_{Cap}}$

- $MP_{Lab} = \frac{\partial q_{Out}}{\partial q_{Lab}}$

- $MP_{Mat} = \frac{\partial q_{Out}}{\partial q_{Mat}}$

On peut facilement calculer ces productivit√©s marginales avec la fonction `cobbDouglasDeriv`.

```{r}
#| label: cd_prod_mp
#| code-fold: false
cd_prod_margProducts <- cobbDouglasDeriv(
    c("qCap", "qLab", "qMat"),
    data = apples, coef = coef(cd_prod)[1:4],
    coefCov = vcov(cd_prod)[1:4, 1:4]
)
```

```{r}
#| label: cd_prod_mp_table
#| echo: false
cd_prod_margProducts$deriv |>
    as_tibble() |>
    rowid_to_column() |>
    gt() |>
    cols_label(
        rowid = md("$N$"),
        qCap = md("$MP_{Cap}$"),
        qLab = md("$MP_{Lab}$"),
        qMat = md("$MP_{Mat}$")
    ) |>
    fmt_number(-rowid) |>
    fmt_integer(rowid, pattern = "Producteur {x}") |>
    cols_align("center") |>
    tab_header(
        title = md("**Productivit√©s marginales**"),
        subtitle = md("*Dans le cadre d'une fonction de production `Cobb-Douglas`*")
    ) |>
    tab_options(
        table.background.color = bg_color
    ) |>
    opt_interactive(use_highlight = TRUE)
```

- *Par exemple*, pour le producteur 1 : 
  - L'augmentation d'une unit√© de **capital** tout en maintenant constant le niveau de travail et de mat√©riaux entra√Ænera une augmentation de 6.23 unit√©s d'output.
  - L'augmentation d'une unit√© de **travail** tout en maintenant constant le niveau de capital et de mat√©riaux entrainera une augmentation de 6.03 unit√©s d'output.
  - L'augmentation d'une unit√© de **mat√©riaux** tout en maintenant constant le niveau de travail et de capital entrainera une augmentation de 59.09 unit√©s d'output.

> On remarque dans ce mod√®le que la productivit√© marginale des mat√©riaux est sup√©rieure √† celle du capital et du travail **pour tous les producteurs**. De plus, aucune productivit√© marginale n'est n√©gative, c'est √† dire que rajouter des quantit√©s de n'importe quel input sans augmenter les autres r√©sultera toujours en une augmentation de la production.

### Fonction de production quadratique

:::{.callout-tip}

## Forme de la fonction

$$
q_i = \alpha + \sum_{k=1}^3\beta_k x_{ik} + \frac{1}{2}\sum_{l=1}^3\sum_{k=1}^3 \beta_{kl}x_{ik}x_{il} + Œµ_i
$$

- La **fonction de production quadratique** dans notre cas s'√©crit donc sous la forme :

$$
\begin{gathered}q_{Out}‚Äã=Œ±+Œ≤_1‚Äãq_{Cap}‚Äã+Œ≤_2‚Äãq_{Lab}‚Äã+Œ≤_3‚Äãq_{Mat}\\
‚Äã+\frac{1}{2}‚Äã(Œ≤_{11}‚Äãq^2_{Cap}‚Äã+Œ≤_{22}‚Äãq^2_{Lab}‚Äã+Œ≤_{33}‚Äãq^2_{Mat})\\
‚Äã+‚ÄãŒ≤_{12}‚Äãq_{Cap}‚Äãq_{Lab}‚Äã+Œ≤_{13}‚Äãq_{Cap}‚Äãq_{Mat}‚Äã+Œ≤_{23}‚Äãq_{Lab}‚Äãq_{Mat}‚Äã+Œµ_i‚Äã
\end{gathered}
$$

:::

**‚úÖ Avantages :** 

- La fonction de production quadratique va permettre d'ajouter des termes *quadratiques* et des effets d'*interaction*, rendant la mod√©lisation plus robuste.

**‚ùå Inconv√©nients :** 

- L'ajout de termes suppl√©mentaires implique plus de complexit√© et de coefficients √† estimer $(3^2 = 9)$.

```{r}
#| label: quad_prod
#| code-fold: false
quad_prod <- quadFuncEst(
    "qOut",
    c("qCap", "qLab", "qMat"),
    data = apples
)
```

```{r}
#| label: quad_prod_table
#| echo: false
gtgazer(
    quad_prod,
    n_coef = 9,
    coefnames = c("$\\alpha$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_{11}$", "$\\beta_{12}$", "$\\beta_{13}$", "$\\beta_{22}$", "$\\beta_{23}$", "$\\beta_{33}$"),
    description = c(
        "- Constante du mod√®le",
        "- Coefficient associ√© √† la variable `qCap`",
        "- Coefficient associ√© √† la variable `qLab`",
        "- Coefficient associ√© √† la variable `qMat`",
        "- Coefficient associ√© √† la variable `qCap¬≤`",
        "- Coefficient associ√© √† la variable `qCap√óqLab`",
        "- Coefficient associ√© √† la variable `qCap√óqMat`",
        "- Coefficient associ√© √† la variable `qLab¬≤`",
        "- Coefficient associ√© √† la variable `qLab√óqMat`",
        "- Coefficient associ√© √† la variable `qMat¬≤`"
    ),
    title = "**Fonction de production quadratique**",
    bg_color = bg_color
) |> fmt_number(
    columns = coefficients,
    rows = c(5:9),
    decimals = 5,
    drop_trailing_zeros = TRUE
)
```

```{r}
#| label: quad_prod_metrics
#| echo: false
apples <- apples |> mutate(
    qCap2 = 0.5 * qCap^2,
    qLab2 = 0.5 * qLab^2,
    qMat2 = 0.5 * qMat^2
)

quad_prod_2 <- lm(
    qOut ~ qCap + qLab + qMat +
        qCap2 + qLab2 + qMat2 +
        I(qCap * qLab) + I(qLab * qMat) + I(qMat * qCap),
    data = apples
)

aic_quad_prod <- AIC(quad_prod_2)
bic_quad_prod <- BIC(quad_prod_2)
loglik_quad_prod <- logLik(quad_prod_2)[1]
```

- Le coefficient associ√© √† `qCap` est de 5.27, mais il n'est pas statistiquement significatif, ce qui sugg√®re que la quantit√© de capital n'a pas une influence significative sur la production totale dans ce mod√®le.

- Le coefficient associ√© √† `qLab` est de 6.077 avec un niveau de significativit√© assez faible, ce qui signifie que pour chaque unit√© suppl√©mentaire de travail utilis√©e, la production totale augmente en moyenne de 6.077 unit√©s, *toutes choses √©gales par ailleurs*.

- Le coefficient associ√© √† `qMat` est de 14.303, mais il n'est pas statistiquement significatif, ce qui sugg√®re que la quantit√© de mat√©riaux n'a pas une influence significative sur la production totale dans ce mod√®le.

- Le coefficient associ√© √† l'effet d'interaction entre les quantit√©s de capital et de travail (`qCap√óqLab`) est n√©gatif et significatif au seuil de 5%. Cela sugg√®re que l'interaction entre ces 2 facteurs a un effet n√©gatif sur la production.

- Le coefficient associ√© √† l'effet d'interaction entre les quantit√©s de tavail et de mat√©riaux (`qLab√óqMat`) est positif et significatif au seuil de 1%. Cela sugg√®re que l'interaction entre ces 2 facteurs a un effet positif sur la production.

- Enfin, le coefficient associ√© √† l'effet quadratique des mat√©riaux (`qMat¬≤`) est statistiquement significatif au seuil 5% et poss√®de une valeur n√©gative, ce qui sugg√®re une courbe de rendement d'√©chelle d√©croissante pour les mat√©riaux, indiquant que l'augmentation de la quantit√© de mat√©riaux pourrait initialement augmenter la production, mais √† un rythme d√©croissant.

$R^2_{adj} =$ 0.834 donc 83.4% de la variance de la production totale est expliqu√©e par la variance des variables explicatives. Ce r√©sultat est meilleur que la fonction de production lin√©aire.

```{r}
#| label: heterosced_investigate_quad
#| echo: false
predicted_qOut <- predict(quad_prod) |>
    as_tibble() |>
    rename(predicted_qOut = value)
qOut <- apples |> select(qOut)

residuals <- resid(quad_prod) |>
    as_tibble() |>
    rename(residuals = value)

bind_cols(qOut, predicted_qOut, residuals) |>
    mutate(diff = predicted_qOut / qOut) |>
    arrange(diff) |>
    gt() |>
    tab_header(title = md("üîé Comparaison de la **production effective** et de la **production pr√©dite**")) |>
    cols_label(
        qOut = md("$q_{Out}$"),
        predicted_qOut = md("$\\widehat{q_{Out}}$"),
        residuals = md("$\\varepsilon_i$"),
        diff = md("$\\widehat{q_{Out}}/q_{Out}$")
    ) |>
    fmt_number(suffixing = TRUE, n_sigfi = 2) |>
    cols_align("center") |>
    tab_options(
        table.background.color = bg_color
    ) |>
    opt_interactive(use_highlight = TRUE)
```

```{r}
#| label: vif_quad
#| warning: false
#| echo: false
#| fig-align: center
collinearity_quad <- check_collinearity(quad_prod_2, verbose = FALSE) |>
    as_tibble() |>
    mutate(
        Term = case_when(
            Term == "qCap2" ~ "qCap¬≤",
            Term == "qLab2" ~ "qLab¬≤",
            Term == "qMat2" ~ "qMat¬≤",
            Term == "I(qCap * qLab)" ~ "qCap√óqLab",
            Term == "I(qLab * qMat)" ~ "qLab√óqMat",
            Term == "I(qMat * qCap)" ~ "qMat√óqCap",
            .default = as.character(Term)
        )
    )

ggplot(collinearity_quad, aes(x = Term, y = VIF)) +
    geom_point(size = 3.5, color = "darkred") +
    geom_pointrange(aes(ymin = VIF_CI_low, ymax = VIF_CI_high), color = "darkred") +
    geom_rect(aes(xmin = 0, xmax = 10, ymin = 10, ymax = Inf), fill = "red", alpha = 0.01) +
    geom_rect(aes(xmin = 0, xmax = 10, ymin = 5, ymax = 10), fill = "blue", alpha = 0.01) +
    geom_rect(aes(xmin = 0, xmax = 10, ymin = 0, ymax = 5), fill = "green", alpha = 0.01) +
    labs(
        title = "Etude des VIF",
        subtitle = "Pour la fonction de production quadratique",
        x = "",
        y = ""
    )
```

Les valeurs de **VIF** sont ici **extr√™mement √©lev√©es**. La forme fonctionnelle du mod√®le avec interactions et effets quadratiques entra√Æne naturellement ces forts probl√®mes de multicolin√©arit√©.

```{r}
#| label: posterior_quad
#| fig-align: center
posterior_predictive_check(quad_prod_2)
```

On semble √™tre dans une situation de **surapprentissage**, en effet le mod√®le s'ajuste trop par rapport aux donn√©es sur lesquelles il a √©t√© entrain√©, il g√©n√©ralise donc mal et est tr√®s sensible au bruit.

#### Rendements d'√©chelle

Cette fois, pour calculer les rendements d'√©chelle, il faut v√©rifier la relation existant entre :

$$
\begin{gathered}
f(\lambda q_{Cap}, \lambda q_{Lab}, \lambda q_{Mat},\\ \lambda q_{Cap}^2, \lambda q_{Lab}^2, \lambda q_{Mat}^2,\\ \lambda q_{Cap}q_{Lab}, \lambda q_{Cap}q_{Mat}, \lambda q_{Lab}q_{Mat})
\end{gathered}
$$ {#eq-scales-1}

et

$$
\begin{gathered}
\lambda \times f(q_{Cap}, q_{Lab}, q_{Mat},\\ q_{Cap}^2, q_{Lab}^2, q_{Mat}^2, \\q_{Cap}q_{Lab}, q_{Cap}q_{Mat}, q_{Lab}q_{Mat})
\end{gathered}
$$ {#eq-scales-2}

::: {.callout-note}

## Note sur les rendements d'√©chelle

- **D√©croissants** si @eq-scales-1 $<$ @eq-scales-2

- **Constants** si @eq-scales-1 $=$ @eq-scales-2

- **Croissants** si @eq-scales-1 $>$ @eq-scales-2

:::

**TRES BANCAL**

```{r}
#| label: quad_return_scale
lambda <- rep(3, 140)

quad_prod_3 <- lm(
    qOut ~ lambda * qCap + lambda * qLab + lambda * qMat +
        qCap2 + qLab2 + qMat2 +
        I(qCap * qLab) + I(qLab * qMat) + I(qMat * qCap),
    data = apples
)

quad_x1 <- predict(quad_prod_2)
quad_x2 <- predict(quad_prod_3)

quad_x2 / quad_x1
```

#### Productivit√© marginale des inputs

```{r}
#| label: quad_prod_mp
#| code-fold: false
quad_prod_margProducts <- quadFuncDeriv(
    c("qCap", "qLab", "qMat"),
    data = apples,
    coef = coef(quad_prod),
    coefCov = vcov(quad_prod)
)
```

```{r}
#| label: quad_prod_mp_table
#| echo: false
quad_prod_margProducts |>
    as_tibble() |>
    rowid_to_column() |>
    gt() |>
    cols_label(
        rowid = md("$N$"),
        qCap = md("$MP_{Cap}$"),
        qLab = md("$MP_{Lab}$"),
        qMat = md("$MP_{Mat}$")
    ) |>
    fmt_number(-rowid) |>
    fmt_integer(rowid, pattern = "Producteur {x}") |>
    cols_align("center") |>
    tab_header(
        title = md("**Productivit√©s marginales**"),
        subtitle = md("*Dans le cadre d'une fonction de production `quadratique`*")
    ) |>
    tab_options(
        table.background.color = bg_color
    ) |>
    opt_interactive(use_highlight = TRUE)
```

> Cette fois on remarque qu'il existe des **productivit√©s marginales n√©gatives**. Prenons l'exemple du producteur 1. Si celui-ci d√©cide d'ajouter une unit√© de capital en maintenant les autres inputs constants (travail et mat√©riaux), alors sa production va diminuer de 3.07 unit√©s.

### Fonction de production Translog

:::{.callout-tip}

## Forme de la fonction

$$
\begin{gathered} \ln(q_i) = \alpha + \sum_{k=1}^3\beta_k\ln(x_{ik})\\ 
+ \frac{1}{2}\sum_{l=1}^3\sum_{k=1}^3 \beta_{kl}\ln(x_{ik})ln(x_{il}) + Œµ_i
\end{gathered}
$$

- La **fonction de production Translog** dans notre cas s'√©crit donc sous la forme :

$$
\begin{gathered}\ln(q_{Out})‚Äã=Œ±+Œ≤_1 \ln(‚Äãq_{Cap})‚Äã+Œ≤_2 \ln(‚Äãq_{Lab})‚Äã+Œ≤_3 \ln(‚Äãq_{Mat})\\
‚Äã+\frac{1}{2}‚Äã\left(Œ≤_{11}\ln(‚Äãq^2_{Cap})‚Äã+Œ≤_{22}\ln(‚Äãq^2_{Lab})‚Äã+Œ≤_{33}\ln(‚Äãq^2_{Mat})\right)\\
‚Äã+‚ÄãŒ≤_{12}\ln(‚Äãq_{Cap}‚Äãq_{Lab})‚Äã+Œ≤_{13}‚Äã\ln(q_{Cap}‚Äãq_{Mat})‚Äã+Œ≤_{23}\ln(‚Äãq_{Lab}‚Äãq_{Mat})‚Äã+Œµ_i‚Äã
\end{gathered}
$$

:::

```{r}
#| label: translog_prod
#| code-fold: false
translog_prod <- translogEst(
    "qOut",
    c("qCap", "qLab", "qMat"),
    data = apples
)
```

```{r}
#| label: translog_prod_table
#| echo: false
gtgazer(
    translog_prod,
    n_coef = 10,
    coefnames = c("$A$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$", "$\\beta_{11}$", "$\\beta_{12}$", "$\\beta_{13}$", "$\\beta_{22}$", "$\\beta_{23}$", "$\\beta_{33}$"),
    description = c(
        "- Constante du mod√®le",
        "- Coefficient associ√© √† la variable `qCap`",
        "- Coefficient associ√© √† la variable `qLab`",
        "- Coefficient associ√© √† la variable `qMat`",
        "- Coefficient associ√© √† la variable `qCap¬≤`",
        "- Coefficient associ√© √† la variable `qCap√óqLab`",
        "- Coefficient associ√© √† la variable `qCap√óqMat`",
        "- Coefficient associ√© √† la variable `qLab¬≤`",
        "- Coefficient associ√© √† la variable `qLab√óqMat`",
        "- Coefficient associ√© √† la variable `qMat¬≤`"
    ),
    title = "**Fonction de production Translog**",
    bg_color = bg_color
)
```

**Cons√©quence** : L'estimation par moindres carr√©s ordinaires d'une forme flexible comme la fonction *Translog* donne des r√©sultats assez m√©diocres.

En effet, seulement 3 coefficients sont significatifs au seuil de 10% :

- `qCap√óqLab`

- `qCap√óqMat`

- `qLab¬≤`

- Le $R^2_{adj}$ est un peu plus elev√© que celui de la *Cobb-Douglas*, autour de 0.6. 


#### Co√ªt marginal de la production

Le **co√ªt marginal** correspond √† la fabrication d'une unit√© suppl√©mentaire d'output (`qOut`).

La fonction `translogProdFuncMargCost` nous permet d'estimer ces co√ªts marginaux dans le cadre d'une fonction de production *Translog*.

::: {.callout-note}

## Informations sur les co√ªts marginaux

- Si le co√ªt marginal est tr√®s proche de 0, cela signifie que produire plus ne co√ªte que tr√®s peu cher au producteur. On s'attend donc √† ce que les installations qui produisent le plus de pommes aient un co√ªt marginal $\simeq 0$ gr√¢ce aux √©conomies d'√©chelles qu'ils r√©alisent.

- Si le co√ªt marginal est $< 0$, cela signifie que produire moins co√ªte plus √† l'entreprise. Dans ce cas l'entreprise a int√©r√™t √† produire plus jusqu'√† atteindre un co√ªt marginal proche de 0.

- Si le co√ªt marginal est $> 0$, alors il faut que le producteur compare le prix `pOut` qu'il peut obtenir et son co√ªt marginal pour d√©cider si il doit ou non produire davantage.

:::

```{r}
#| label: margcost_chunk
#| code-fold: false
margCost <- translogProdFuncMargCost(
    yName = "qOut",
    xNames = c("qCap", "qLab", "qMat"),
    wNames = c("pCap", "pLab", "pMat"),
    data = apples, coef = coef(translog_prod)
)
```

```{r}
#| label: margcost_table
#| echo: false
margCosts <- margCost |>
    as_tibble() |>
    rowid_to_column() |>
    rename(marg_cost = value)

bind_cols(margCosts, apples |> select(pOut, qOut)) |>
    gt() |>
    cols_label(
        rowid = md("$N$"),
        marg_cost = md("$MC$"),
        pOut = md("$p_{Out}$"),
        qOut = md("$q_{Out}$"),
    ) |>
    fmt_number(-rowid, suffixing = TRUE) |>
    fmt_integer(rowid, pattern = "Producteur {x}") |>
    cols_align("center") |>
    tab_header(
        title = md("**Co√ªt marginal de la production**"),
        subtitle = md("*Note* : Quand $CM > p_{Out}$, la ligne est mise en surbrillance")
    ) |>
    data_color(
        columns = marg_cost,
        rows = marg_cost > pOut,
        palette = "darkred",
        alpha = 0.75
    ) |>
    tab_options(
        table.background.color = bg_color
    ) |>
    opt_interactive(use_highlight = TRUE)
```

#### V√©rification des conditions de r√©gularit√©

> **En premier lieu, on peut v√©rifier la monotonie de la fonction.**

```{r}
#| label: translog-mono
#| code-fold: false
mono <- translogCheckMono(
    c("qCap", "qLab", "qMat"),
    data = apples,
    coef = coef(translog_prod),
    increasing = TRUE
)
```

$\Rightarrow$ Cette fonction de production **Translog** augmente de mani√®re monotone dans les facteurs de production `qCap`, `qLab`, `qMat`, dans 65,7% des observations.

***

> **En second lieu, on peut v√©rifier si la fonction de production est quasi-concave.**

*La quasi-concavit√© garantit que la production r√©agit de mani√®re d√©croissante aux augmentations marginales des inputs. Autrement dit, une augmentation marginale d'un input entra√Æne une augmentation marginale de la production qui d√©cro√Æt au fur et √† mesure que cet input augmente.*

```{r}
#| label: translog-curv
#| code-fold: false
curv <- translogCheckCurvature(
    c("qCap", "qLab", "qMat"),
    data = apples,
    coef = coef(translog_prod),
    convexity = FALSE,
    quasi = TRUE
)
```

$\Rightarrow$ Cette fonction de production **Translog** est quasi-concave dans 45% des observations.

### Fonction de production CES

:::{.callout-tip}

## Forme de la fonction

$$
q_i = \gamma \left(\sum^3_{i=1}\delta_k x_{ik}^{-\rho}\right)^{-\frac{1}{\rho}} + \varepsilon_i
$$

- La **fonction de production CES** dans notre cas s'√©crit donc sous la forme :

$$
q_{Out} = \gamma\left[\delta \cdot \left(\delta_1 q_{Cap}^{-\rho_1}+ (1-\delta_1)q_{Lab}^{-\rho_1}\right)^{\frac{\rho}{\rho_1}} +(1-\delta)q_{Mat}^{-\rho} \right]^{-{\frac{1}{\rho}}} + \varepsilon_i
$$

:::

De part sa d√©finition, la fonction **CES** est √† rendements d'√©chelle constants.

```{r}
#| label: ces_prod
#| code-fold: false
ces_prod <- cesEst(
    "qOut",
    c("qCap", "qLab", "qMat"),
    data = apples,
    method = "SANN",
    returnGrad = TRUE
)
```

```{r}
summary(ces_prod)

aes_ces_prod <- round(ces_prod$ela[2], 2)

durbinWatsonTest(ces_prod)
```

L'√©lasticit√© de substitution est ici √©gale √† **`r aes_ces_prod`**. Celle-ci √©tant sup√©rieure √† 1, cela signifie que les 3 facteurs de productions `qCap`, `qLab` et `qMat` sont fortement substituables dans ce mod√®le. En d'autres termes, une augmentation du prix relatif d'un facteur (par exemple de `qCap`) entra√Ænera une substitution vers un autre facteur (`qLab` ou `qMat`).

### Fonction de production SFA 

Dans le mod√®le **SFA** *(Stochastic Frontier Analysis)*, on introduit un terme multiplicatif $TE_i$. Ce terme repr√©sente l‚Äôefficacit√© technique, d√©finie comme le ratio d‚Äôoutput observ√© sur l‚Äôoutput
maximum r√©alisable, soit : $TE_i = \frac{q_i}{q_i^*}$. 

- On peut r√©-√©crire ce $TE_i$ sous la forme $\exp\left\{-u_i\right\}$.

> **Utiliser un tel mod√®le va donc nous permettre de pouvoir estimer l'efficacit√© technique producteur par producteur.**

*Note* : Nous pouvons utiliser plusieurs formes fonctionnelles pour ce mod√®le, sous la contrainte que notre variable √† pr√©dire soit mise sous forme logarithmique, ce qui √©limine *de facto* les mod√®les de production lin√©aire et quadratique.

::: {.callout-tip}

## Forme de la fonction

$$
q_i = A\prod_{k=1}^3x_{ik}^{a_k}\cdot 
\underbrace{\exp\left\{-u_i\right\} \cdot \exp\left\{v_i\right\}}_{\varepsilon_i}
$$

- La fonction de production **SFA Cobb-Douglas** dans notre cas s‚Äô√©crit donc sous la forme :

$$
q_{Out} = A\cdot q_{Cap}^\alpha \cdot q_{Lab}^\beta \cdot q_{Mat}^\gamma \cdot \exp\left\{-u_i\right\} \cdot \exp\left\{v_i\right\}
$$

En lin√©arisant on obtient : 

$$
\ln(q_{out}) = \ln(A) + \alpha \cdot \ln(q_{Cap}) + \beta \cdot \ln(q_{Lab}) + \gamma \cdot \ln(q_{Mat}) + v_i - u_i
$$

:::

```{r}
#| label: cd_sfa
#| code-fold: false
cd_sfa <- sfa(log(qOut) ~ log(qCap) + log(qLab) + log(qMat), data = apples)
```

```{r}
#| label: cd_sfa_table
#| echo: false
cd_sfa_loglik <- round(summary(cd_sfa)$mleLogl, 3)
cd_sfa_mean_eff <- round(mean(efficiencies(cd_sfa)), 3)

summary(cd_sfa)$mleParam |>
    as_tibble() |>
    slice(1:4) |>
    add_column(
        coefnames = c("$A$", "$\\alpha$", "$\\beta$", "$\\gamma$"),
    ) |>
    mutate(signif = makestars(`Pr(>|z|)`)) |>
    gt(rowname_col = "coefnames") |>
    fmt_number(decimals = 3) |>
    cols_add(description = c(
        "- Constante du mod√®le",
        "- Coefficient associ√© √† la variable `qCap`",
        "- Coefficient associ√© √† la variable `qLab`",
        "- Coefficient associ√© √† la variable `qMat`"
    )) |>
    cols_move_to_start(description) |>
    cols_hide("z value") |>
    fmt_markdown(description) |>
    fmt_markdown(coefnames) |>
    fmt_markdown(signif) |>
    cols_label(
        description = md("**Description**"),
        Estimate = md("**Coefficients**"),
        `Std. Error` = md("**Ecart Type**"),
        `Pr(>|z|)` = md("**Pvalues**"),
        signif = md("**Significativit√©**")
    ) |>
    tab_header(
        title = md("**Fonction de production Cobb-Douglas SFA**"),
        subtitle = md("Variable d√©pendante : `qOut`")
    ) |>
    tab_footnote(
        footnote = md("*Observations : 140*")
    ) |>
    tab_footnote(
        footnote = md("***")
    ) |>
    tab_footnote(
        footnote = md(glue::glue("**Log-Vraisemblance** $=$ {cd_sfa_loglik}"))
    ) |>
    tab_footnote(
        footnote = md(glue::glue("**Efficacit√© moyenne** $=$ {cd_sfa_mean_eff}"))
    ) |>
    tab_options(
        table.background.color = bg_color
    )
```

- On remarque que les coefficients et les niveaux de significativit√© trouv√©s par l'estimateur du maximum de vraisemblance sont tr√®s proches de ceux de la Cobb-Douglas estim√©s par **OLS** dans la @sec-cobb-prod.

#### Analyse de l'efficacit√© technique des producteurs

L'efficacit√© technique moyenne des 140 producteurs est de 0.538, c'est √† dire qu'il y a certainement un nombre important de producteurs *"inefficients"*.

En utilisant l‚Äôesp√©rance conditionnelle $E(\exp(‚àíu_i)|\epsilon_i)$, on peut estimer le score d‚Äôefficacit√©
pour chaque observation. Dans ce cas, les estimations d'efficacit√© ont des valeurs comprises entre z√©ro et un, o√π un indique que le producteur de pommes est **pleinement efficace** dans sa production et z√©ro indique que le producteur est **totalement inefficace**.

```{r}
#| label: effic
#| code-fold: false
efficiencies <- efficiencies(cd_sfa) |> as_tibble()
```

```{r}
#| label: efficiency_plot
#| echo: false
#| fig-align: center

apples <- bind_cols(apples, efficiencies)

apples |>
    filter(qOut < 15000000) |>
    ggplot() +
    aes(y = qOut, x = efficiency) +
    geom_point(colour = "darkorchid") +
    labs(
        title = "Relation entre l'efficacit√© des producteurs et l'output",
        subtitle = "Note : Les 2 producteurs dont la production est sup√©rieure √† 15M sont exclus",
        x = "Efficacit√©",
        y = expression(q[Out]),
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    ) +
    geom_smooth(
        method = "lm",
        formula = y ~ x
    )
```

- Le graphique ci-dessus nous permet de constater qu'en moyenne, plus la production est elev√©e, plus l'efficacit√© du producteur estim√©e par le mod√®le **Cobb-Douglas SFA**  le sera √† son tour. N√©anmoins, les producteurs dont la production est tr√®s importante ne sont pourtant pas les plus efficaces techniquement comme le montrent les quelques points qui se d√©tachent de la tendance lin√©aire.

#### Tests statistiques

Le test de rapport de vraisemblance est un test d'hypoth√®se qui compare l'ad√©quation de l'ajustement de deux mod√®les afin de d√©terminer celui qui offre le meilleur ajustement. Dans notre cas, on veut comparer le mod√®le **Cobb-Douglas** estim√© par *Moindres Carr√©s Ordinaires* et le mod√®le **Cobb-Douglas SFA** estim√© par la m√©thode du *Maximum de Vraisemblance*. 

Les hypoth√®ses du test sont les suivantes :
$$
\begin{cases}
H_0: \text{Modele } 1 \Rightarrow \text{Ordinary Least Squares}\\
H_1: \text{Modele } 2 \Rightarrow \text{Error Component Frontier}
\end{cases}
$$

```{r}
#| label: lrtest_cd_sfa
#| echo: false
lrtest_cd_sfa <- lrtest(cd_sfa)
likelihood_models <- round(lrtest_cd_sfa$LogLik, 3)
pvalue_lrtest_cd_sfa <- round(lrtest_cd_sfa$`Pr(>Chisq)`[2], 3)
```

La statistique de test est $\lambda_{LR} = 2\cdot(\ln \mathcal{L}_1-\ln \mathcal{L}_2)$

- $\mathcal{L}_1 =$ `r likelihood_models[1]`

- $\mathcal{L}_2 =$ `r likelihood_models[2]`

$\Rightarrow$ Au risque $\alpha = 5\%$, la $p-value$ issue du test est √©gale √† `r pvalue_lrtest_cd_sfa` $< 0.05$, **on rejette donc l'hypoth√®se nulle $H_0$, c'est √† dire que le mod√®le de fronti√®re de production Cobb-Douglas offre un meilleur ajustement.**

### Machine Learning de production

::: {.callout-tip}

## Random Forest

√Ä titre exp√©rimental, il est envisageable d'explorer l'utilisation du **Machine Learning** pour √©tudier la production de pommes. 

Cependant, compte tenu du peu de donn√©es disponibles, cette approche n'est pas id√©ale. Nous envisageons n√©anmoins d'appliquer un algorithme de **Random Forest**. Ce mod√®le permet d'extraire l'importance des variables, offrant ainsi une certaine transparence dans le fonctionnement de ce mod√®le de Machine Learning souvent per√ßu comme une bo√Æte noire.

Comme pour les fonction de production nous tentons d'expliquer la variable `qOut` √† partir des variables `qLab`, `qCap` et `qMat`.

:::

- Effectuons un **train-test split** sur nos donn√©es.

```{r}
#| label: machine_learning
#| code-fold: false
apples_ML <- apples |> select(qOut, qCap, qLab, qMat)
split <- apples_ML |> initial_split(prop = 2 / 3)
df_train <- split |> training()
df_test <- split |> testing()
```

```{r}
#| label: best_model_old
#| echo: false
# task <- makeRegrTask(data = df_train, target = "qOut")

# Tuning
# estimateTimeTuneRanger(task)
# rf <- tuneRanger(task,
#                 tune.parameters = c("mtry", "min.node.size"),
#                 num.trees = 1000)

# Best model
# params <- rf$recommended.pars
```

```{r}
#| label: random_forest
#| code-fold: false
best_model <- ranger(
    formula = qOut ~ .,
    data = df_train,
    mtry = 1,
    min.node.size = 2,
    importance = "permutation"
)
```

```{r}
#| label: ml_metrics
#| echo: false
pred <- predict(best_model, data = df_test)$predictions
metric_mae <- mean(abs(pred - df_test$qOut))
metric_r2 <- 1 - sum((pred - df_test$qOut)^2) / sum((mean(df_test$qOut) - df_test$qOut)^2)
```

Le coefficient de d√©termination $R^2$ associ√© √† ce mod√®le de Random Forest est de **`r round(metric_r2,3)`**, ce qui est similaire au score que nous avions obtenu pr√©c√©demment.

Avec le graphique ci-dessous, nous pouvons comparer les valeurs pr√©dites et les valeurs r√©elles. Lorsqu'un point est parfaitement align√© avec la ligne en pointill√©s rouge, le mod√®le fait la bonne pr√©diction. Cependant, si le point est au-dessus (resp. en-dessous) de la ligne, cela signifie que le mod√®le a sous-estim√© (resp. surestim√©) `qOut`.

```{r}
#| label: compare_preds
#| echo: false
#| fig-align: center
ggplot() +
    aes(x = pred, y = df_test$qOut) +
    geom_point() +
    geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
    labs(
        x = "Pr√©diction", y = "R√©alit√©", title = "Comparaison pr√©diction vs. r√©alit√©",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    ) +
    scale_x_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    )
```

Lorsque l'on examine l'importance des variables, on observe que la variable `qLab` exerce le plus grand impact dans le mod√®le Random Forest, tandis que la variable `qCap` a le moins d'influence. C'est tr√®s int√©ressant car la variable `qLab` est syt√©matiquement significative dans les mod√®les pr√©c√©dent.

```{r}
#| label: ml_importance
#| echo: false
#| fig-align: center
importance <- best_model$variable.importance |>
    as.data.frame()

ggplot(
    data = importance,
    aes(
        x = fct_reorder(
            row.names(importance),
            best_model$variable.importance
        ),
        y = best_model$variable.importance
    )
) +
    geom_bar(stat = "identity", fill = "royalblue", alpha = 0.5, width = 0.3) +
    labs(
        x = "Variables", y = "Importance", title = "Importance des variables",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    coord_flip() +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    )
```

En r√©sum√©, dans notre contexte, le Machine Learning ne semble pas apporter une valeur ajout√©e significative. Le mod√®le obtenu n'est pas plus performant que les mod√®les pr√©c√©dents, et nous perdons l'avantage de disposer de coefficients associ√©s √† chaque variable.

## Fonctions de co√ªt

> Une fonction de co√ªt repr√©sente la relation entre les quantit√©s des diff√©rents facteurs de production utilis√©s (ici `qCap`, `qLab`, `qMat`) et le co√ªt total de production (ici `vCap + vLab + vMat`).

En fait, celle-ci donne le co√ªt minimum associ√© √† un niveau d'output et de prix des inputs, en tenant compte de la technologie disponible.

Calculons d'abord le co√ªt total des inputs, c'est √† dire $v_{Cap} + v_{Lab} + v_{Mat}$.

```{r}
#| label: total_cost
#| code-fold: false
apples <- apples |> mutate(cost = vCap + vLab + vMat)
```

### Fonction de co√ªt Cobb-Douglas 

:::{.callout-tip}

## Forme de la fonction
$$
c_i = A \prod_{k=1}^{3} p_{ik}^{\alpha_k}q_i^{\alpha_y} \varepsilon_i
$$

- Dans notre cas la fonction de co√ªt Cobb-Douglas s'√©crit : 

$$
c_i = A \cdot q_{Out}^{\alpha_1} \cdot p_{Cap}^{\alpha_2} \cdot p_{Lab}^{\alpha_3} \cdot p_{Mat}^{\alpha_4} \cdot \epsilon_i
$$

En lin√©arisant on obtient :

$$
\ln(c_i) = \ln(A) + \alpha_1 \cdot \ln(q_{out}) +\alpha_2 \cdot \ln(p_{Cap})+\alpha_3 \cdot \ln(p_{Lab})+\alpha_4 \cdot \ln(p_{Mat}) + \ln(\epsilon_i)
$$

:::

```{r}
#| label: cobb_cost
#| code-fold: false
cobb_cost <- translogCostEst(
    cName = "cost",
    yName = "qOut",
    pName = c("pCap", "pLab", "pMat"),
    apples, homPrice = FALSE,
    linear = TRUE
)
```

```{r}
#| label: cobb_cost_table
#| echo: false
gtgazer(
    cobb_cost,
    n_coef = 4,
    coefnames = c("$A$", "$\\alpha_1$", "$\\alpha_2$", "$\\alpha_3$", "$\\alpha_4$"),
    description = c(
        "- Constante du mod√®le",
        "- Coefficient associ√© √† la variable `qOut`",
        "- Coefficient associ√© √† la variable `pCap`",
        "- Coefficient associ√© √† la variable `pLab`",
        "- Coefficient associ√© √† la variable `pMat`"
    ),
    title = "**Fonction de co√ªt Cobb Douglass**",
    bg_color = bg_color
)
```

-  Le coefficient de 0.373 pour `qOut` signifie que si la production augmente de 1%, le co√ªt total augmentera de 0.373%, *ceteris paribus*.

- Le coefficient de `pLab` est de 0.464. Cela indique qu'une augmentation d'1% du prix du travail cela entraine une augmentation d'environ 0.464% du co√ªt total, *ceteris paribus*.

- Le coefficient de `pMat` est de 0.486. Il indique qu'une augmentation d'1% du prix des mat√©riaux entraine une augmentation d'environ 0.486% du co√ªt total, *ceteris paribus*.

Seul le coefficient associ√© √† la variable `pCap` n'est pas significatif, les autres le sont √† 5 % et 10 % pour `pLab`.

### Fonction de co√ªt Cobb-Douglas de court terme

La fonction de court terme est elle d√©finie par l'immutabilit√© d'au moins un facteur de production. Dans notre contexte, le capital est fixe, ce qui nous permet de la caract√©riser ainsi.

:::{.callout-tip}

## Forme de la fonction
$$
c_i = A x_{i3}^{\alpha_f}\prod_{k=1}^{2} p_{ik}^{\alpha_k}q_i^{\alpha_y} \varepsilon_i
$$

- Dans notre cas la fonction de co√ªt Cobb-Douglas de court terme s'√©crit : 

$$
c_i = A \cdot q_{Out}^{\alpha_1} \cdot q_{Cap}^{\alpha_4} \cdot p_{Lab}^{\alpha_2} \cdot p_{Mat}^{\alpha_3} \cdot \epsilon_i
$$

En lin√©arisant on obtient :

$$
\ln(c_i) = \ln(A) + \alpha_1 \cdot \ln(q_{out}) +\alpha_4 \cdot \ln(q_{Cap})+\alpha_2 \cdot \ln(p_{Lab})+\alpha_3 \cdot \ln(p_{Mat}) + \ln(\epsilon_i)
$$

:::

```{r}
#| label: cobb_cost_ct
#| code-fold: false
cobb_cost_ct <- translogCostEst(
    cName = "cost",
    yName = "qOut",
    pName = c("pLab", "pMat"),
    fNames = "qCap",
    data = apples,
    homPrice = FALSE,
    linear = TRUE
)
```

```{r}
#| label: cobb_cost_ct_table
#| echo: false
gtgazer(
    cobb_cost_ct,
    n_coef = 4,
    coefnames = c("$A$", "$\\alpha_1$", "$\\alpha_2$", "$\\alpha_3$", "$\\alpha_4$"),
    description = c(
        "- Constante du mod√®le",
        "- Coefficient associ√© √† la variable `qOut`",
        "- Coefficient associ√© √† la variable `pLab`",
        "- Coefficient associ√© √† la variable `pMat`",
        "- Coefficient associ√© √† la variable `qCap`"
    ),
    title = "**Fonction de co√ªt Cobb Douglass de court terme**",
    bg_color = bg_color
)
```

-  Le coefficient de 0.279 pour `qOut` signifie que si la production augmente de 1%, le co√ªt de augmentera de 0.279%, toutes choses √©tant √©gales par ailleurs. On remarque donc que √† court terme la variation de la quantit√© produite √† moins d'impact sur le co√ªt que √† long terme.

- Le coefficient de la variable `qCap` est de 0.237, cela indique qu'une augmentation de 1% de la quantit√© de capital entraine une augmentation de 0.237% du co√ªt total. A court terme, la quantit√© de capital a un impact positif et significatif sur le co√ªt de production.

- Les prix du travail (`pLab`) et des mat√©riaux (`pMat`) ont un impact moins important sur le co√ªt total √† court terme que √† long terme, on le remarque car les coefficients sont moins √©lev√©s √† court terme.


### Fonction de co√ªt Translog *(PARTIE BANCALE)*

:::{.callout-tip}

## Forme de la fonction

$$
\begin{gathered}
\ln(c_i) = \alpha + \sum_{k=1}^3 \beta_k \ln(p_{ik}) + \alpha_q \ln(q_i) \\ +\frac{1}{2}\sum_{l=1}^3\sum_{k=1}^3\beta_{kl}\ln(p_{ik})\ln(p_{il})\frac{1}{2}\alpha_{q}(\ln(q_i))^2 \\
+\frac{1}{2}\sum_{k=1}^3\alpha_{kq}\ln(p_{ik})\ln(q_i)+\varepsilon_i
\end{gathered}
$$

- Dans notre cas la fonction de co√ªt Translog s'√©crit : 

$$
\begin{gathered}\ln(c_{i}) =\alpha+\beta_2 \ln(p_{Cap})+\beta_3 \ln(p_{Lab})+\beta_4 \ln(p_{Mat}) + \beta_1\ln(q_{Out}) +\\
\left[\frac{1}{4}\beta_{11}(\ln(q_{Out}))^2\right] \\ [(\beta_{22}\ln(p^2_{Cap})+\beta_{33}\ln(p^2_{Lab})+\beta_{44}\ln(p^2_{Mat})
+\beta_{23}\ln(p_{Cap}p_{Lab})+\beta_{24}\ln(p_{Cap}p_{Mat})+\beta_{34}\ln(p_{Lab}p_{Mat})] + \\
\frac{1}{2}[\beta_{12}\ln(p_{Cap})\ln(q_{Out})+ \beta_{13}\ln(p_{Lab})\ln(q_{Out}) + \beta_{14}\ln(p_{Mat})\ln(q_{Out})]+\varepsilon_i
\end{gathered}
$$


:::

```{r}
#| label: translog_cost_ct
#| code-fold: false
translog_cost <- translogCostEst(
    cName = "cost",
    yName = "qOut",
    pName = c("pCap", "pLab", "pMat"),
    apples, homPrice = FALSE
)
```

```{r}
#| label: translog_cost_ct_table
#| echo: false
gtgazer(
    translog_cost,
    n_coef = 9,
    coefnames = c(
        "$\\alpha$",
        "$\\beta_1$",
        "$\\beta_2$",
        "$\\beta_3$",
        "$\\beta_4$",
        "$\\beta_{11}$",
        "$\\beta_{12}$",
        "$\\beta_{13}$",
        "$\\beta_{14}$",
        "$\\beta_{22}$",
        "$\\beta_{23}$",
        "$\\beta_{24}$",
        "$\\beta_{33}$",
        "$\\beta_{34}$",
        "$\\beta_{44}$"
    ),
    description = c(
        "`Intercept`",
        "`qOut`",
        "`pCap`",
        "`pLab`",
        "`pMat`",
        "`qOut¬≤`",
        "`qOut*pCap`",
        "`qOut*pLab`",
        "`qOut*pMat`",
        "`pCap¬≤`",
        "`pCap*pLab`",
        "`pCap*pMat`",
        "`pLab¬≤`",
        "`pLab*pMat`",
        "`pMat¬≤`"
    ),
    title = "**Fonction de co√ªt Translog**",
    bg_color = bg_color
)
```

- On remarque qu'avec une fonction de co√ªt Translog, le co√ªt d√©pend majoritairement de la quantit√© produite, on le constate avec la significativit√© des coefficients associ√©s √† `qOut` et `qOut^2`.

## Profit des producteurs

$$
\pi = (p_{Out} \cdot q_{Out}) - \overbrace{(v_{Cap} + v_{Lab} + v_{Mat})}^{cost}
$$

```{r}
#| label: profit_formula
#| code-fold: false
apples <- apples |> mutate(profit = (pOut * qOut) - cost)
```

::: {.callout-note}

- Les producteurs dont le profit d√©passe 5 millions sont mis en surbrillance [**verte**]{style="color:darkgreen;"}.

- Les producteurs dont le profit est n√©gatif sont en mis subrillance [**rouge**]{style="color:darkred;"}.

:::

```{r}
#| label: profit_tbl
#| echo: false

profit_tbl <- apples |>
    select(pOut, qOut, cost, profit) |>
    rowid_to_column() |>
    arrange(desc(profit)) |>
    select(rowid, profit)

profit_tbl |>
    gt() |>
    cols_label(
        rowid = md("$N$"),
        profit = md("$\\pi$")
    ) |>
    fmt_number(-rowid, suffixing = TRUE) |>
    fmt_integer(rowid, pattern = "Producteur {x}") |>
    cols_align("center") |>
    tab_header(
        title = md("**Profit des producteurs de pommes**")
    ) |>
    data_color(
        columns = profit,
        rows = profit < 0,
        palette = "darkred",
        alpha = 0.75
    ) |>
    data_color(
        columns = profit,
        rows = profit > 5000000,
        palette = "darkgreen",
        alpha = 0.75
    ) |>
    tab_options(
        table.background.color = bg_color
    ) |>
    opt_interactive(use_highlight = TRUE)
```

```{r}
#| label: profit_metrics
#| echo: false

negative_profit <- profit_tbl |>
    filter(profit < 0) |>
    count() |>
    pull()

five_million_profit <- profit_tbl |>
    filter(profit > 5000000) |>
    count() |>
    pull()

min_profit <- profit_tbl |> filter(profit == min(profit))
max_profit <- profit_tbl |> filter(profit == max(profit))

avg_profit <- profit_tbl |>
    summarise(mean = mean(profit)) |>
    pull() |>
    round(2)

median_profit <- profit_tbl |>
    summarise(median = median(profit)) |>
    pull() |>
    round(2)

min_producer <- min_profit |>
    select(rowid) |>
    pull()
max_producer <- max_profit |>
    select(rowid) |>
    pull()
```

**On remarque tout de m√™me qu'il y a d'importantes diff√©rences de profits entre les producteurs.** 

En effet, il y a **`r negative_profit`** producteurs de pommes ayant un profit n√©gatif et **`r five_million_profit`** producteurs dont le profit est sup√©rieur √† 5 millions.

- Le profit moyen $\bar\pi$ quant √† lui est de **`r format(avg_profit, scientific = F)`**.

- Le profit m√©dian $\tilde\pi$, bien inf√©rieur, est de **`r format(median_profit, scientific = F)`**.

Enfin, le **producteur `r min_producer`** poss√®de le profit le moins elev√© du panel et le **producteur `r max_producer`** poss√®de le profit le plus elev√© *(voir le tableau ci-dessus)*.

```{r}
#| label: pi_median
#| echo: false
pi_med_adv <- apples |>
    filter(adv == 1) |>
    pull(profit) |>
    median()

pi_med_noadv <- apples |>
    filter(adv == 0) |>
    pull(profit) |>
    median()
```

On remarque quelque chose d'int√©ressant : la m√©diane des profits des producteurs recevant des conseils est bien plus √©lev√©e (**`r format(pi_med_adv, scientific = F)`**) que ceux ne recevant pas de conseils (**`r format(pi_med_noadv, scientific = F)`**)

```{r}
#| label: pi_advice
#| echo: false
#| fig-align: center
apples |>
    select(pOut, qOut, cost, profit, adv_chr) |>
    mutate(CA = pOut * qOut) |>
    ggplot() +
    aes(y = profit, fill = adv_chr) +
    geom_boxplot() +
    labs(
        title = "Profit en fonction de conseils ou non.",
        y = "Profit",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    )
```

> Nous pouvons aussi nous int√©resser au nuage de points des profits et des quantit√©s produites.

```{r}
#| label: qout_profit_corr
#| echo: false
qout_profit_corr <- apples |>
    select(qOut, profit) |>
    cor() |>
    as_tibble() |>
    select(profit) |>
    slice(1) |>
    pull() |>
    round(2)
```

*Note* : Etant donn√© la corr√©lation de **`r qout_profit_corr`** entre `profit` et `qOut`, on s'attend √©videmment √† ce que produire plus de pommes entra√Æne n√©cessairement un acroissement du profit. 

```{r}
#| label: profit_qout
#| fig-align: center
#| echo: false
ggplot(apples, aes(x = qOut, y = profit, color = efficiency)) +
    geom_point() +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    ) +
    scale_x_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    ) +
    scale_color_continuous(trans = "reverse") +
    labs(
        x = expression(q[Out]),
        y = expression(pi),
        title = "Relation entre le profit et l'output",
        subtitle = "Les points les plus fonc√©s repr√©sentent les producteurs les plus efficaces techniquement (SFA)",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    theme(legend.position = "none")
```

## Co√ªt moyen (PARTIE a am√©liorer)

Le co√ªt moyen repr√©sente le co√ªt total (`cost`) de la firme divis√© par son niveau d'output (`qOut`).

```{r}
#| label: mean_cost
#| code-fold: false
apples <- apples |> mutate(CM = cost / qOut)
```

```{r}
ggplot(apples, aes(x = qOut, y = cost, color = CM)) +
    geom_point()
```

On peut √©galement tracer les courbes correspondant √† la recette totale (RT) et au co√ªt total (CT). La relation entre RT et la quantit√© produite est estim√©e de mani√®re `quadratique` alors que la relation entre le CT et la quantit√© produite est une relation `lin√©aire`. Les points correspondent aux donn√©es r√©elles. On constate que le profit est dans un premier temps n√©gatif puis devient positif (partie gris√©e). Ce petit mod√®le permet de constater √† partir de quelle quantit√© produite un arboriculteur commence √† faire du profit.

*On remarque aussi visuellement les rendements d'√©chelle croissants*

```{r}
#| label: pi_study_lines
#| echo: false
#| fig-align: center
qOut_MAX <- 2000000

etude <- apples |>
    filter(qOut < qOut_MAX) |>
    select(pOut, qOut, cost, profit, adv_chr) |>
    mutate(RT = pOut * qOut)

quadra_rt <- lm(RT ~ qOut + I(qOut^2), etude)
quadra_rt_coefs <- quadra_rt$coefficients
linear_ct <- lm(cost ~ qOut, etude)
linear_ct_coefs <- linear_ct$coefficients

qOut <- seq(0, qOut_MAX, by = 1000)
func_RT <- quadra_rt_coefs[1] + quadra_rt_coefs[2] * qOut + quadra_rt_coefs[3] * qOut^2
func_CT <- linear_ct_coefs[1] + linear_ct_coefs[2] * qOut

datoum <- data.frame(qOut = qOut, func_RT = func_RT, func_CT = func_CT)

ggplot() +
    geom_line(data = datoum, aes(x = qOut, y = func_RT), color = "red", lwd = 1) +
    geom_line(data = datoum, aes(x = qOut, y = func_CT), color = "blue", lwd = 1) +
    geom_point(data = etude, aes(x = qOut, y = RT), alpha = 0.1, color = "red") +
    geom_point(data = etude, aes(x = qOut, y = cost), alpha = 0.1, color = "blue") +
    geom_ribbon(
        data = subset(datoum, func_RT > func_CT),
        aes(x = qOut, ymin = func_CT, ymax = func_RT),
        fill = "black", alpha = 0.1
    ) +
    labs(
        x = expression(q[Out]), y = "RT & CT", title = "Etude du profit",
        caption = "Auteurs : @Corentin DUCLOUX, @Guillaume DEVANT, 2024 "
    ) +
    annotate(
        geom = "text", x = qOut_MAX * 0.95, y = max(func_CT) * 2,
        label = "Profit", color = "black", fontface = "bold"
    ) +
    annotate(
        geom = "text", x = qOut_MAX * 0.95, y = max(func_RT),
        label = "Recette Totale", color = "red"
    ) +
    annotate(
        geom = "text", x = qOut_MAX * 0.95, y = max(func_CT) * 0.65,
        label = "Co√ªt Total", color = "blue"
    ) +
    scale_y_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    ) +
    scale_x_continuous(
        labels = scales::label_number(
            scale_cut = scales::cut_short_scale()
        )
    )
```


### Fonction de profit Quadratique Normalis√©e Sym√©trique

Using the netput notation (where outputs are positive and inputs are treated as negative)

```{r}
apples_snq <- apples |>
    select(N, pOut, pCap, pLab, pMat, qOut, qCap, qLab, qMat) |>
    mutate(qCap = -qCap, qLab = -qLab, qMat = -qMat)

snq_func <- snqProfitEst(
    priceNames = c("pOut", "pCap", "pLab", "pMat"),
    quantNames = c("qOut", "qCap", "qLab", "qMat"),
    data = apples_snq,
)

snq_func_convex <- snqProfitImposeConvexity(snq_func)

snq_func_convex

predict(snq_func_convex)
```


## Infos sur le sujet | ROADMAP

$\Rightarrow$ Estimer somehow la leontieff g√©n√©ralis√©e, v√©rifier h√©t√©rosc√©dasticit√©.

Propri√©t√© de la CD => si la fonction de prod est cobb douglas, alors la fonction de co√ªt l'est aussi.

- [ ] Rendements d'√©chelle (somme des exposants) => on peut trouver ces rendements d'√©chelle soit en faisant la fonction de co√ªt, ou la fonction de production. Mais on peut aussi les estimer grace √† une fonction de demande

**DEUX CHOSES ESSENTIELLES**

- Il faut estimer les substitutions entre facteurs
- Les rendements d'√©chelle

### Notes sur la translog Cost

On pourrait tt √† fait estimer le syst√®me d'√©quations suivant :

Voir aussi la slide 78 sur la fonction $\ln C$

$$
\begin{cases}
S_1 = \alpha_1 + \sum^3_{i=1} \beta_{1j}\ln p_j + \beta_{1y}\ln y\\
S_2 = \alpha_2 + \sum^3_{i=1} \beta_{2j}\ln p_j + \beta_{2y}\ln y\\
S_3 = \alpha_3 + \sum^3_{i=1} \beta_{3j}\ln p_j + \beta_{3y}\ln y
\end{cases}
$$

Inconv√©nients dans la translog et les formes flexibles : 

Le nombre de param√®tres explose √† cause des effets crois√©s et risque important de collin√©arit√©.

Quand on passe au syst√®me au tableau, on a augment√© √† 3*140 donn√©es (420 observations) et on a un peu moins de param√®tres

[done]{style="color:red;"}